\section{Approach}
In this section, I'll describe all of my design choices when planning and implementing this project.

\subsection{Algorithm}
I first implemented Yao's Garbled Circuits with the permute-and-point optimization. Next, I added the Row Reduction and Free XOR optimizations. I decided not to pursue Half Gates or Garbled Gadgets due to time constraints. Implementing the remaining state-of-the-art optimization techniques would be a good candidate for future work.

I chose to keep the project general-purpose, such that it could execute for any circuit definition within the hardware limits (more on limits in Sec.~\ref{sec:hw}). This is in contrast to a ``baked-in'' approach where I choose one circuit to garble, and hard-code it into the FPGA as an accelerator for only that computation. Algorithmically, this means that the circuit definition needs to be reconsidered dynamically every execution time.

My implementation uses a streaming approach, wherein the first line of the circuit definition file is interpreted, computed, and transmitted before the next line is even read. This is in contrast to an in-memory approach which would read the entire file, perform all computations, then transmit all messages. This means that the size of the circuit is not a concern for the garbler, and the evaluator can simply pass off the network traffic to the FPGA as it comes in. Considering that (useful) circuits can easily be larger than a typical consumer-oriented computer's memory, streaming is essential to scalability.

\subsection{Protocol}
I embraced the ``semi-honest'' model, in which the two parties behave correctly, but are ``curious'' about the information which should be hidden from them. This means that I can define the garbler-evaluator protocol without added security in mind to prevent the parties from acting maliciously. I therefore designed a protocol that makes many assumptions about the other party, like that they run the same version of the software and aim to evaluate the same circuit.

These last two assumptions are fine for development and testing, but any real application would require sending at least the software version and the circuit definition file's hash before starting the transaction. Once both parties have the same definition file, the order of transmission of data structures is the same every time, so there is no need for packet framing and metadata beyond what's inherent in TCP. The parties communicate over a socket that could be local, LAN, or across the internet, and I leave packetizing, buffering, and various transmission guarantees to the TCP/IP stack.

First, the garbler (Alice) listens for incoming connections. Once a socket is established, Alice sends her garbled inputs to Bob (the evaluator). Bob then requests his inputs bit-by-bit through oblivious transfers with Alice. After this setup phase, since the gate types and wire IDs are already provided in-order in the circuit definition, Alice sends Bob \textit{only} the AND gate ciphertexts as she computes them. Finally, once all the gate definitions have been transmitted, Alice sends a hash of each output wire's False label. Bob hashes his own output labels and compares them to the hashes received from Alice. For each wire, if the hash matches, then Bob knows that the output value on that wire is False. If the hash does not match, the output is True. Bob the recombines these True and False values as a binary number to form the output of the computation.

Communication between Bob's smartphone and FPGA is more complicated since it doesn't have access to the circuit definition file. The circuit definition can be considered a set of instructions for the co-processor to execute, and sending these ahead of execution time would add significant design overhead for the storage and access of these instructions. Instead, opcodes (the gate type), operands (the gate ID and input wire IDs), and data (ciphertexts when the gate is an AND gate) are all transmitted over the same serial connection. Each instruction is packed with the gate type first, then the input IDs (or just one ID in the case of a buffer gate), the ciphertexts if present, and finally the gate ID. In addition to the gate type instructions, there are also instructions to set the read/write head, write a wire label, and read a wire label. The writing is used to provide the FPGA with the initial garbled inputs, and the reading occurs at the end to report the calculation result to the smartphone.

\subsection{Software}
I wrote the garbler and evaluator code in Python. An interpreted language is obviously not ideal for a performance-oriented project, but Python's simplicity proved valuable for debugging and rapid prototyping. With more time or in a following project, I would re-implement the functionality in Rust or C. I made some design decisions with a language migration in mind, like avoiding libraries beyond the standard library and any esoteric features.

I also made some software design decisions to make the hardware definition steps easier. For example, I learned and re-implemented AES rather than relying on OpenSSL or some other cryptography library. This made the project more of an academic exercise than a typical software engineering process.

\subsubsection{Oblivious Transfer}
I first implemented the RSA public-key cryptosystem in Python, then used it as a library to implement an oblivious transfer API that uses sockets. The implementation was straightforward.

I originally intended to replace the RSA public-key backend with elliptic curves (ECC), but ultimately prioritized other aspects of the project. This is another area for future improvements, since the ECC cryptosystem allows sending much smaller keys between parties while maintaining the same level of security.

\subsubsection{Advanced Encryption Standard}
One of my initial goals was to thoroughly understand and then implement the Advanced Encryption Standard (AES). To this end, I did not use a well-audited library like OpenSSL and instead implemented the underlying mathematics directly. In my first design iteration, I computed every operation without lookups with the exception of the S-box. After profiling the performance, I discovered that the Galois field multiplication in the MixColumns step was a tight bottleneck. I replaced the function with a table lookup to improve performance dramatically.

I could have replaced the other round operations with table lookups to reach a ``T-tables'' implementation, but after implementing this technique in hardware, I decided to leave the software AES functions in their more readable state describing the distinct operations that compose AES rounds.

\subsubsection{Garbler}
The garbler role is fulfilled by a single-client server. It listens for new connections, performs a fresh Garbled Circuits computation with any client that connects, then returns to waiting idle for the next client. Since my testing and development only ever had one client and one server at a time, there was no need to implement a full FastCGI or WSGI interface. In the cloud-provider model, a scalable server architecture would be more appropriate, but this was not an implementation goal. Calling my libraries from a web server like Flask would make writing a WSGI implementation of the garbler role simple.

\subsubsection{Evaluator}
I implemented the evaluation logic three ways. First, I write idiomatic Python code in software alone. Next, I wrote an FPGA emulator (also in Python) and modified the evaluation logic to send properly-packed coprocessor instructions to the emulated device. Finally, once I had finished the hardware implementation, I simply swapped the endpoint from the emulated coprocessor to the real one.

In the default configuration, the evaluator script checks for the presence of the coprocessor, and falls back to the software implementation if needed.

\subsection{Hardware}\label{sec:hw}
I chose the Pine64 Pinephone\cite{Pinephone}\footnote{Allwinner A64 quad-core SoC, 3GB RAM, USB 2.0 over type-C} for the mobile smartphone platform since it fully supports a typical Linux environment, allowing me to use the same source code for the client and server\footnote{8-core Intel Xeon E3-1505M CPU, 32GB RAM (evaluator is the bottleneck)} software. The Pinephone also includes a USB port accessible to userspace tools in the same way as on a typical laptop or desktop, meaning that the interface to the coprocessor is the same regardless of the platform. I chose the iCEBreaker FPGA development board\cite{iCEBreaker} (with the Lattice iCE40 UP5K FPGA chip\cite{LatticePage}) for its low cost, low power consumption, open-source board design, open-source development toolchain\footnote{\url{https://github.com/YosysHQ}} (utilities listed in Tab.~\ref{tab:versions}), and accessible community.

I prioritized finding an open-source option because of the importance of public audits for all security-related code. One downside of using the open-source toolchain is that closed-source pre-designed modules (IP cores) cannot realistically be sold or licensed for use. This is not a concern for me because of my goal of allowing total audits and because I do not need the convenience of drop-in solutions like Ethernet controllers or other high-complexity high-performance components that would require the proprietary expertise of the manufacturer.

\begin{table}[ht]
	\centering
	\begin{tabular}{l c c c}
		\toprule
		Utility       & Executable                         & Version  & Commit \\
		\midrule
		IceStorm      & \texttt{icepack}, \texttt{iceprog} & r777     & \texttt{c495861} \\
		Yosys         & \texttt{yosys}                     & 0.9+4052 & \texttt{0ccc722} \\
		Next Gen P\&R & \texttt{nextpnr}                   & r3529    & \texttt{5a41d20} \\
		\bottomrule
	\end{tabular}
	\caption{FPGA toolchain utility versions. ``P\&R'' is an abbreviation of ``Place and Route.'' All tools were built from source from the GitHub commit matching the hash in the right column. These tools can be found on the Yosys Open SYnthesys Suite GitHub page: \url{github.com/YosysHQ}}%
	\label{tab:versions}
\end{table}

\subsubsection{Execution}

I used an event-based design inside the FPGA rather than a central control unit that issues control signals with fixed timings. For example, the memory controller emits a signal when it has finished fetching a value, and this signal is fed to the next component which uses the fetched value. Sequential and combinational logic considering the current gate type determines which ``done'' signals are forwarded to ``start'' signals.

There are only six instructions: set address, read, write, AND, XOR, and BUF. The first three are for direct memory access (DMA) over the serial connection for setting inputs, reading outputs, and debugging. The latter three instructions are garbled gates to evaluate. Each gate instruction begins with the gate type (opcode), then the wire ID for each input. In the case of the AND instruction, $128*3=384$ bits of ciphertexts follow. All gate instructions end with the gate ID, which is also the wire ID at which to store the gate's output. Since there are so few instructions, and the most common instructions (the gates) each do multiple memory operations, this coprocessor can be considered to have a CISC (complex instruction set computer) architecture.

\begin{figure}[ht]
	\centering
	\input{figures/architecture.tex}
	\caption{Simplified coprocessor architecture. The main memory-memory logic is implemented in the bottom center. The behavior of the three multiplexers on the bottom over time determine which gate (instruction) is being evaluated.}%
	\label{fig:arch}
\end{figure}

A high-level overview of the architecture is shown if Fig.~\ref{fig:arch}. The serial signal enters through the SPI module into an encoder/decoder, which breaks each instruction down into its fields and strobes control lines when each field is received. When the wire ID of an input is received, the memory controller fetches the wire label stored at that address. If it is the second wire ID of the gate and it is an XOR gate, then the second fetched wire label is combined with the first with XOR, and the result is held until the gate ID (destination wire label address) is received. The result is then stored at that address.

If the gate type is an AND gate, then the two fetched values are combined to form the input to the AES hash function and the point-and-permute pointer. Once the AES encryption is complete (which occurs while the first ciphertext is being received), the hash is held until the index of the most recently received ciphertext matches the point-and-permute pointer, at which point they are combined with XOR and the result is held until the gate ID arrives. In all cases, the final result is stored as soon as the gate ID arrives.

%There is no need for a multiple-issue pipeline since instructions arrive more slowly than they can be processed. If the ciphertexts and gate definitions could be sent many times faster, their execution could be parallelized with a very similar structure to the current coprocessor design.

\subsubsection{Pipelines and Memory}
The coprocessor has a memory-memory architecture: instructions operate on the contents of memory without any general-purpose registers. Each garbled gate evaluation requires one or two memory reads and one memory write, with two or three address therefore specified within each instruction. Memory operations are done in the order of addresses within the instruction as the instruction is read in from serial byte-wise.

These memory operations are individually pipelined. Memory is used for the AES lookup tables and for the wire label storage. Unfortunately, the very nature of each gate instruction and the AES T-table lookups present load-and-use hazards that require waiting for dependencies and inserting pipeline bubbles. Each AES round requires two memory operations since there is only enough RAM width to support looking up half of the values in the state array at a time, so while these two operations can be pipelined, there is no way to keep the memory pipeline full across rounds. This also means that there would be no speed penalty to performing each round in three lookups instead of two, since the second lookup of one round could take place while the first lookup of the next round enters the pipeline, filling the bubble.

Even combining all four SPRAM blocks to create a wire label array only offers the bit width to accommodate half of a wire label, so memory accesses to the wire label array are also pipelined as two operations.

\subsubsection{Limitations}
My choice of FPGA development platform placed many restrictions on my implementation. For example, I only have room on the fabric to provision a module capable of performing half of an AES round in a single clock cycle. On a larger FPGA, I would have enough room to fully unroll the algorithm's loops and perform all AES rounds in a single clock cycle. Similarly, I would have more options for fast inputs and outputs.

Right now the design uses on-chip SPRAM for wire label storage, which only has space to safely store 8192 wire labels. It effectively functions as a direct-mapped cache without a larger memory device to back it. This means that any gate in the garbled circuit which requests an input wire with an ID more than several thousand addresses behind the gate ID runs the risk of having the desired wire label overwritten. This issue can be easily detected in software during execution or as a preprocessing/validation step, but the much better solution is to use more RAM.

\subsubsection{Scalability}
The event-based architecture makes it trivial to integrate a new memory controller for a larger bank of memory. The standard expansion port (PMOD) on the development board makes adding RAM simple, though a new driver would be required on the fabric.

Similarly, a faster AES implementation relying on more lookup tables or an unrolled loop would easily slot into the current design without the concern for tweaking timings or delays in other components.
